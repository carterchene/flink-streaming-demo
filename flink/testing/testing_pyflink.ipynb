{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c941bb0-40ee-4ca0-a0f7-8cfab69864a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import StreamTableEnvironment\n",
    "from pyflink.table.expressions import col, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687df192-96f0-4b0d-812f-8776c2001a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the streaming environment\n",
    "s_env = StreamExecutionEnvironment.get_execution_environment()\n",
    "\n",
    "# add the kafka connector \n",
    "s_env.add_jars(\"file:///C:/Users/Carter%20Dakota/portfolio/downloads/flink-sql-connector-kafka-3.2.0-1.19.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c496c3-b7a7-4bb4-9c96-f5e207efd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the table environment for configuring in SQL\n",
    "t_env = StreamTableEnvironment.create(s_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "431e060c-9871-43f3-b8c1-30b7c0298eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x21d1f459950>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the source\n",
    "t_env.execute_sql(\"\"\"\n",
    "    CREATE TABLE kafka_source (\n",
    "        `song` string ,\n",
    "        `artist` string ,\n",
    "        `duration` double ,\n",
    "        `ts` bigint ,\n",
    "        `sessionId` INTEGER ,\n",
    "        `auth` string ,\n",
    "        `level` string ,\n",
    "        `itemInSession` INTEGER ,\n",
    "        `city` string ,\n",
    "        `zip` string ,\n",
    "        `state` string ,\n",
    "        `userAgent` string ,\n",
    "        `lon` double ,\n",
    "        `lat` double ,\n",
    "        `userId` integer ,\n",
    "        `lastName` string ,\n",
    "        `firstName` string ,\n",
    "        `gender` string ,\n",
    "        `registration` BIGINT\n",
    "    ) WITH (\n",
    "        'connector' = 'kafka',\n",
    "        'topic' = 'listen_events',\n",
    "        'properties.bootstrap.servers' = '3.96.62.156:9092',\n",
    "        'properties.group.id' = 'flink-consumer-group-1', \n",
    "        'scan.startup.mode' = 'earliest-offset',\n",
    "        'format' = 'json'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3eb694-06ca-4b2a-b064-f7eb708347f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x21d1f430650>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "    CREATE TABLE listen_events_s3 (\n",
    "        `song` string ,\n",
    "        `artist` string ,\n",
    "        `duration` double ,\n",
    "        `ts` bigint ,\n",
    "        `sessionId` INTEGER ,\n",
    "        `auth` string ,\n",
    "        `level` string ,\n",
    "        `itemInSession` INTEGER ,\n",
    "        `city` string ,\n",
    "        `zip` string ,\n",
    "        `state` string ,\n",
    "        `userAgent` string ,\n",
    "        `lon` double ,\n",
    "        `lat` double ,\n",
    "        `userId` integer ,\n",
    "        `lastName` string ,\n",
    "        `firstName` string ,\n",
    "        `gender` string ,\n",
    "        `registration` BIGINT\n",
    "        ) WITH (\n",
    "            'connector' = 'filesystem',\n",
    "            'path' = 's3://streaming-demo-project/outputs',\n",
    "            'format' = 'parquet',\n",
    "            'sink.rolling-policy.file-size' = '128MB',\n",
    "            'sink.rolling-policy.rollover-interval' = '15 min',\n",
    "            'sink.rolling-policy.check-interval' = '1 min',\n",
    "            'partition.time-extractor.timestamp-pattern'='$year-$month-$day 00:00:00',\n",
    "            'sink.partition-commit.delay'='1 h',\n",
    "            'sink.partition-commit.policy.kind'='success-file'\n",
    "        )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75bda571-91cb-47a1-9015-28909dfb94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_source = t_env.from_path('kafka_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d51721-ca3f-48c8-9874-b074d353955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x21d1f432dd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "        INSERT INTO sink_print\n",
    "        SELECT *\n",
    "        FROM kafka_source; \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d39bc137-5072-46c6-bb9f-0c6a16533a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = t_env.from_path('print')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84f9a2-11d2-45ca-8882-4598e8f82d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59221a9-7b13-4f3d-9e80-5ea422187f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
